---
image: "media/nnet_big.svg"
output:
  html_document:
    toc: yes
    toc_float:
        collapsed: true
        smooth_scroll: true
    theme: flatly
    code_folding: hide
    highlight: espresso
    css: www/css/custom.css
    includes:
      in_header: header.html
  word_document:
    toc: yes
editor_options:
  chunk_output_type: console
always_allow_html: true
---
```{css, echo=FALSE}
 #TOC::before {
  font-size: 32px;
  font-weight: 900;
  text-align: center; 
  content: "sentiment.ai";
  display: block;
  width: 200px;
  height: 80px;
  line-height: 80px;
  margin: 10px 10px 10px 20px;
  //background-image: url("media/nnetsmall.png");
  background-size: contain;
  background-position: center center;
  background-repeat: no-repeat;
}
#TOC{
    border:none;
}

```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(reticulate)
require(sentiment.ai)
#sentiment.ai.init(model = "en.large")
assign("depthtrigger", 4, data.table:::.global)
```
```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
require(knitr)
require(kableExtra)
require(magrittr)
require(formattable)
require(data.table)


colLight <- "#1cb1c4"
colMed   <- "#2b8cbe"
colDark  <- "#4158CD"
colDarkest <- "#09001c"
```
<h1 class="title toc-ignore">
sentiment<span class="rainbow-text">.ai</span>
</h1>
<h1 class="subtitle toc-ignore rainbow-text"> Open Source AI-Based Sentiment Analysis</h1>
<br>


## Overview

We made `sentiment.ai` for researchers and tinkerers who want a straight-forward way to
use open source deep learning models to improve their sentiment analyses. We've wrapped a lot of the 
underlying hassle up to make the process as simple as possible. In addition to just being cool, this approach solves several problems with traditional sentiment analysis, namely: 

1) It is **case-insensitive**, can **handle spelling mitsakes**, and can be applied to **16 languages**! 

2) It **doesn't need to match words to a ridged lexicon**, rather it matches to an embedding vector (reduces language to a vector of numbers that capture the information, kind of like a PCA). This means you can get scores for words that are not in the lexicon but are similar to existing words! 

3) You can **choose the context** for what negative and positive mean. For example, you could set `positive` to mean `"high quality"` and negative to mean `"low quality"` when looking at product reviews.


4) **Power** Because it draws from models trained on billions of texts, news articles, and wikipedia entries, it is able to detect things such as *"I learned so much on my trip to Hiroshima museum last year!"* is associated with something positive and that *"What happeded to the people of Hiroshima in 1945"* is associated with something negative. 


### Simple Example

```{r example1, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
# Load the package
require(sentiment.ai)
require(SentimentAnalysis)
require(sentimentr)

# Only if it's your first ever time
# sentiment.ai.install()

# Initiate the model
# This will create the sentiment.ai.embed model in your environment
init_sentiment.ai(model = "en.large")


text <- c(
    "What a great car. It stopped working after a week.",
    "Steve Irwin working to save endangered species",
    "Bob Ross teaching people how to paint",
    "Adolf Hitler",
    "That was such a cute dog omg I'm literally crying it was so cute!",
    "u-g-l-y- you ain't got no aliby",
    "the resturant served human flesh",
    "the resturant is my favourite!",
    "the redturanr is my fabourite!",
    "the resturant was my absolute favorite until they gave me food poisoning",
    "The app freezes all the time!",
    "The app is a life saver!",
    "I learned so much on my trip to Hiroshima museum last year!",
    "What happened to the people of Hiroshima in 1945",
    "I had a blast on my trip to Nagasaki",
    "The blast in Nagasaki",
    "I love watching scary horror movies",
    "This package offers so much more nuance to sentiment analysis!",
     "you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)

# sentiment.ai
sentiment.ai.score <- sentiment_score(text)

# From Sentiment Analysis
sentimentAnalysis.score <- analyzeSentiment(text)$SentimentQDAP

# From sentimentr
sentimentr.score <- sentiment_by(get_sentences(text), 1:length(text))$ave_sentiment


example <- data.table(target = text, 
                      sentiment.ai = sentiment.ai.score,
                      sentimentAnalysis = sentimentAnalysis.score,
                      sentimentr = sentimentr.score)
```


```{r draw_kable, echo = FALSE, eval=TRUE, message=FALSE}
ex_draw <- copy(example)

ex_draw$sentiment.ai %<>% round(2)
ex_draw$sentimentAnalysis %<>% round(2)
ex_draw$sentimentr %<>% round(2)


color_func <- function(x, col_high = colLight, col_low = colDarkest ){
    out <- ifelse(x > 0,
                  cell_spec(x, color = colLight, bold = TRUE),
                  ifelse(x < 0,
                         cell_spec(x, color = colDarkest, bold = TRUE),
                         cell_spec(x, color = "#808080", bold = FALSE)))
}

ex_draw[, sentiment.ai := color_func(sentiment.ai)]

ex_draw[, sentimentr := color_func(sentimentr)]

ex_draw[, sentimentAnalysis := color_func(sentimentAnalysis)]


ex_draw  %>%
 kableExtra::kable(escape = F) %>%
 kableExtra::kable_styling() %>%
 scroll_box(width = "100%", height = "600px")
```


## Benchmarks

### Glassdoor

Applied example, estimating whether the text from a glassdoor.com review is positive or negative. 

```{r benchmark_glassdoor, message=FALSE, warning=FALSE, echo=FALSE}

our_scores    <- readRDS("../../docs/test/sentiment_ai_scores.rds")
vshift_scores <- readRDS("../../docs/test/sentimentr_scores.rds")
dict_scores   <- readRDS("../../docs/test/dict_scores.rds")

dict_scores$yhat   <- factor(round(scales::rescale(dict_scores$SentimentQDAP, to=0:1)), levels = c("0","1"))
vshift_scores$yhat <- factor(round(scales::rescale(vshift_scores$ave_sentiment, to=0:1)), levels = c("0","1"))

caret::confusionMatrix(data = our_scores$y_hat, reference = our_scores$y, positive = "1")
caret::confusionMatrix(data = dict_scores$yhat, reference = dict_scores$y, positive = "1")
caret::confusionMatrix(data = vshift_scores$yhat, reference = vshift_scores$y, positive = "1")


```
 

### Airline Tweets

```{r benchmark_airline, message=FALSE, warning=FALSE, echo=FALSE}


our_tweet_scores    <- readRDS("../../docs/test/sentimentai_tweet_scores.rds")
vshift_tweet_scores <- readRDS("../../docs/test/sentimentr_tweet_scores.rds")
dict_tweet_scores   <- readRDS("../../docs/test/dict_tweet_scores.rds")
azure_tweet_scores  <- readRDS("../../docs/test/azure_tweet_scores.rds")

dict_tweet_scores$yhat   <- factor(round(scales::rescale(dict_tweet_scores$SentimentQDAP, to=0:1)), 
                                   levels = c("0","1"))
vshift_tweet_scores$yhat <- factor(round(scales::rescale(vshift_tweet_scores$ave_sentiment, to=0:1)), 
                             levels = c("0","1"))

caret::confusionMatrix(data = our_tweet_scores$y_hat, reference = our_tweet_scores$y, positive = "1")
caret::confusionMatrix(data = dict_tweet_scores$yhat, reference = dict_tweet_scores$y, positive = "1")
caret::confusionMatrix(data = vshift_tweet_scores$yhat, reference = vshift_tweet_scores$y, positive = "1")
caret::confusionMatrix(data = azure_tweet_scores$yhat, reference = azure_tweet_scores$y, positive = "1")

```


## Installation

After installing `sentiment.ai` from CRAN, you will need to make sure you have a compatible python environment for `tensorflow` and `tensorflow-text`. As this can be a cumbersome experience, we included a 
convenience function to install that for you:

`sentiment.ai.install()` 

This only needs to be run the first time you install the package. If you're feeling adventurous, you can modify the environment it will create with the following paramaters:

* `envname` - the name of the virtual environment

* `method` - if you specifically want "conda" or "virtualenv" 

* `gpu` - set to TRUE if you want to run tensorflow-gpu

* `python_version` - The python version used in the virtual environment 

* `modules` - a names list of the dependencies and versions




```{r echo=TRUE, eval=FALSE}

# Just leave this as default unless you have a good reason to change it. 
# This is quite dependent on specific versions of python moduules
sentiment.ai.install()

```

## Basic Usage

### `sentiment_easy`

Returns a vector of sentiment scores. The scores are the maximum closeness (cosine simalirity) to a positive or negative example. If the max similarity was to a negative item, the score is returned as a negative value. 

* `model` two defaults are `en` and `multi`. `en` is a shortcut to Universal Sentence Encoder English (large) which has better performance but only works on English, `multi` is the U.S.E Multi-language (large) that has good performance on 16 different languages. 

* 

* `batch_szie` determines how many rows are processed at a time. On CPU this doesn't change much, but can be important if you installed the GPU version. Put simply, small bathes take longer but use less RAM/VRAM, large batches run faster on GPU but could exhaust VRAM if too large. 

* `environment` if you installed into a custom environment, you can specify it here (ignored if you called `sentiment.ai_init()` in the same session.)

## Initialising

## Models

## Benchmarks

### sentiment.ai

### tiytext/sentimentAnalysis

### sentimentr

### azure


<script src="www/js/collapsible.js"></script>
